from omni.isaac.kit import SimulationApp

from pxr import Usd, Gf, UsdGeom
from omni.isaac.core.utils.stage import (
    add_reference_to_stage,
    is_stage_loading,
    update_stage_async,
    update_stage,
)
import omni
from omni.isaac.core import World
from omni.isaac.quadruped.robots import Anymal
from omni.isaac.core.utils.prims import define_prim, get_prim_at_path
from omni.isaac.core.utils.nucleus import get_assets_root_path
from pxr import Gf, UsdGeom
import time
import omni.appwindow  # Contains handle to keyboard
import numpy as np
import carb
from omni.isaac.core.utils.extensions import enable_extension
import gym
class Environment:
    """
    Class that represents the world, agents, and, objects that can exist in an environment
    """
    def __init__(self, name, action_repeat=1, size=(64,64), seed = 0) -> None:
        # self._world = World()
        self._step = 0
        self._objects = []
        self._agents = []


        # ### copied params
        self._size = size 
        self._action_repeat = action_repeat
        self.reward_range = [-np.inf,np.inf]
        self.action_space = spaces.Discrete(4)
        """
        The following dictionary maps abstract actions from `self.action_space` to 
        the direction we will walk in if that action is taken.
        I.e. 0 corresponds to "right", 1 to "up" etc.
        """
        self._action_to_direction = {
            #linear
            0: np.array([1, 0, 0],[0,0,0]),
            1: np.array([0, 1,0]),
            2: np.array([-1, 0, 0]),
            3: np.array([0, -1,0]),
            #angular
            4: np.array([0, 0, 0], [1,1,1]),
            5: np.array([0, 1,0]),
            6: np.array([-1, 0, 0]),
            7: np.array([0, -1,0]),
        }

    @property
    def observation_space(self):
        spaces = {}
        spaces["image"] = gym.spaces.Box(0, 255, self._size + (3,), dtype=np.uint8)
        return gym.spaces.Dict(spaces)

    @property
    def action_space(self):
        return self.action_space

    def _get_obs(self):
        return {"image": np.zeroslike(self._size)

    def step(self,action):
        unpack_action = self._action_to_direction[action]
        linear_veloc = unpack_action[0]
        angular_veloc = unpack_action[1]

        #ensure agent doesnt leave, if it does kill and reset
        goal = [0,0,0]
        # check if agent is at goal
        terminated = False

        # set reward as dist to goal
        reward = 1

        ovservation = self._get_obs()
        # assert np.isfinite(action).all(), action
        # reward = 0
        # for _ in range(self._action_repeat):
        #     time_step = self._env.step(action)
        #     reward += time_step.reward or 0
        #     if time_step.last():
        #         break
        #
        # obs = dict(time_step.observation)
        # obs = {key: [val] if len(val.shape) == 0 else val for key, val in obs.items()}
        # obs["image"] = self.render()
        # # There is no terminal state in DMC
        # obs["is_terminal"] = False if time_step.first() else time_step.discount == 0
        # obs["is_first"] = time_step.first()
        # done = time_step.last()
        # info = {"discount": np.array(time_step.discount, np.float32)}
        # return obs, reward, done, info

    def reset(self):
        obs = 0
        return obs

    def render(self, *args, **kwargs):
        return None


    # def setup(self):
    #     """
    #     This method should setup the environemnt, models, and spawn all assets
    #     Args: None
    #     Returns: None
    #     """
    #     pass
    #
    # def action_space(self):
    #     pass
    #
    # def observation_space(self):
    #     pass
    #
    # def step(self):
    #     #update objects
    #
    #
    #     #update agents
    #     for agent in self._agents:
    #         #get observations from agent
    #         obs = agent.getobs()
    #         #__________________________ = model.get_action(obs)
    #         linear_veloc, angular_veloc = 0,0
    #         agent.step(linear_veloc, angular_veloc)
    #
    #
    #
    #
    # def reset(self):
    #     """
    #     Resets all objects and agents in the environment
    #     Args: None
    #     Returns: None
    #     """
    #     for obj in self._objects:
    #         obj.reset()
    #     for agent in self._agents:
    #         agent.reset()
    #
    #
